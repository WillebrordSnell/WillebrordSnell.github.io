<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-beta.67" />
    <meta name="theme" content="VuePress Theme Hope" />
    <meta property="og:url" content="https://github.com/WillebrordSnell/keyan/videoDialog/videoDialog.html"><meta property="og:site_name" content=" "><meta property="og:title" content="视频对话方向大论文性质的记录"><meta property="og:description" content="视频对话方向大论文性质的记录 视频对话领域在近几年顶刊上的paper寥寥无几并且在大模型的冲击下许多工作其本质就是换皮，本无打算特地做综述性质的报告，但由于开题和毕业论文需要，故留记录 Information-Theoretic Text Hallucination Reduction for Video-grounded Dialogue 论文地址：https://arxiv.org/abs/2212.05765"><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2023-10-27T10:51:10.000Z"><meta property="article:author" content="Mr.R"><meta property="article:tag" content="视频对话"><meta property="article:published_time" content="2023-10-26T00:00:00.000Z"><meta property="article:modified_time" content="2023-10-27T10:51:10.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"视频对话方向大论文性质的记录","image":[""],"datePublished":"2023-10-26T00:00:00.000Z","dateModified":"2023-10-27T10:51:10.000Z","author":[{"@type":"Person","name":"Mr.R","url":"https://github.com/WillebrordSnell"}]}</script><title>视频对话方向大论文性质的记录 |  </title><meta name="description" content="视频对话方向大论文性质的记录 视频对话领域在近几年顶刊上的paper寥寥无几并且在大模型的冲击下许多工作其本质就是换皮，本无打算特地做综述性质的报告，但由于开题和毕业论文需要，故留记录 Information-Theoretic Text Hallucination Reduction for Video-grounded Dialogue 论文地址：https://arxiv.org/abs/2212.05765">
    <style>
      :root {
        --bg-color: #fff;
      }

      html[data-theme="dark"] {
        --bg-color: #1d1e1f;
      }

      html,
      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="preload" href="/assets/style-7ba79056.css" as="style"><link rel="stylesheet" href="/assets/style-7ba79056.css">
    <link rel="modulepreload" href="/assets/app-cab84357.js"><link rel="modulepreload" href="/assets/videoDialog.html-4eb11120.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-c27b6911.js"><link rel="modulepreload" href="/assets/videoDialog.html-711d697d.js"><link rel="prefetch" href="/assets/index.html-d9458bfe.js" as="script"><link rel="prefetch" href="/assets/intro.html-2e5e4af5.js" as="script"><link rel="prefetch" href="/assets/slides.html-fd5a002b.js" as="script"><link rel="prefetch" href="/assets/202309.html-74c2b100.js" as="script"><link rel="prefetch" href="/assets/202310.html-2458bec6.js" as="script"><link rel="prefetch" href="/assets/maoxuan.html-02808c56.js" as="script"><link rel="prefetch" href="/assets/index.html-bf1750b6.js" as="script"><link rel="prefetch" href="/assets/disable.html-28c49317.js" as="script"><link rel="prefetch" href="/assets/encrypt.html-0f38acb2.js" as="script"><link rel="prefetch" href="/assets/markdown.html-d32d3131.js" as="script"><link rel="prefetch" href="/assets/page.html-d359f584.js" as="script"><link rel="prefetch" href="/assets/index.html-fd34dea5.js" as="script"><link rel="prefetch" href="/assets/dialog.html-67f127ce.js" as="script"><link rel="prefetch" href="/assets/video.html-b54bb940.js" as="script"><link rel="prefetch" href="/assets/index.html-a3a40393.js" as="script"><link rel="prefetch" href="/assets/index.html-3b3fc455.js" as="script"><link rel="prefetch" href="/assets/markdown01.html-8905e9eb.js" as="script"><link rel="prefetch" href="/assets/markdown02.html-054a564a.js" as="script"><link rel="prefetch" href="/assets/index.html-1c6f8d12.js" as="script"><link rel="prefetch" href="/assets/contrastiveLearning.html-9843d401.js" as="script"><link rel="prefetch" href="/assets/multiModal.html-c152230c.js" as="script"><link rel="prefetch" href="/assets/videoRepresentation.html-7e948e5f.js" as="script"><link rel="prefetch" href="/assets/videoUnderstanding.html-8cede748.js" as="script"><link rel="prefetch" href="/assets/Bloodborne.html-ac9206cd.js" as="script"><link rel="prefetch" href="/assets/DeathStranding.html-d5380b1b.js" as="script"><link rel="prefetch" href="/assets/AVSD.html-bc3f49fd.js" as="script"><link rel="prefetch" href="/assets/DDP.html-d779b619.js" as="script"><link rel="prefetch" href="/assets/trick.html-bb31f35e.js" as="script"><link rel="prefetch" href="/assets/index.html-a202766c.js" as="script"><link rel="prefetch" href="/assets/manual01.html-0a8da7f1.js" as="script"><link rel="prefetch" href="/assets/manual02.html-d7e0e274.js" as="script"><link rel="prefetch" href="/assets/manual03.html-fc2fcb88.js" as="script"><link rel="prefetch" href="/assets/index.html-94ec1b0f.js" as="script"><link rel="prefetch" href="/assets/documentnotes01.html-3e3bf028.js" as="script"><link rel="prefetch" href="/assets/documentnotes02.html-b0ab3628.js" as="script"><link rel="prefetch" href="/assets/documentnotes03.html-dffc6ca6.js" as="script"><link rel="prefetch" href="/assets/documentnotes04.html-5c8e168f.js" as="script"><link rel="prefetch" href="/assets/documentnotes05.html-e6c9c3ad.js" as="script"><link rel="prefetch" href="/assets/documentnotes06.html-8351650a.js" as="script"><link rel="prefetch" href="/assets/documentnotes07.html-a1156cd2.js" as="script"><link rel="prefetch" href="/assets/documentnotes08.html-4dd750d8.js" as="script"><link rel="prefetch" href="/assets/documentnotes09.html-c3df51ca.js" as="script"><link rel="prefetch" href="/assets/documentnotes10.html-22d25bd9.js" as="script"><link rel="prefetch" href="/assets/documentnotes11.html-739f34bd.js" as="script"><link rel="prefetch" href="/assets/404.html-33087db7.js" as="script"><link rel="prefetch" href="/assets/index.html-f543ab52.js" as="script"><link rel="prefetch" href="/assets/index.html-edca5983.js" as="script"><link rel="prefetch" href="/assets/index.html-9e922b59.js" as="script"><link rel="prefetch" href="/assets/index.html-5d327b0f.js" as="script"><link rel="prefetch" href="/assets/index.html-64a9f81e.js" as="script"><link rel="prefetch" href="/assets/index.html-1eb7a45d.js" as="script"><link rel="prefetch" href="/assets/index.html-3b8e3fc4.js" as="script"><link rel="prefetch" href="/assets/index.html-c24f66de.js" as="script"><link rel="prefetch" href="/assets/index.html-b28248cf.js" as="script"><link rel="prefetch" href="/assets/index.html-11a8a3d5.js" as="script"><link rel="prefetch" href="/assets/index.html-5f4f46c8.js" as="script"><link rel="prefetch" href="/assets/index.html-3fa1430b.js" as="script"><link rel="prefetch" href="/assets/index.html-50095564.js" as="script"><link rel="prefetch" href="/assets/index.html-170b7dac.js" as="script"><link rel="prefetch" href="/assets/index.html-4450e009.js" as="script"><link rel="prefetch" href="/assets/index.html-cd5496ff.js" as="script"><link rel="prefetch" href="/assets/index.html-bf5da18c.js" as="script"><link rel="prefetch" href="/assets/index.html-789dc91d.js" as="script"><link rel="prefetch" href="/assets/index.html-598316da.js" as="script"><link rel="prefetch" href="/assets/index.html-deffa58c.js" as="script"><link rel="prefetch" href="/assets/index.html-cc90af66.js" as="script"><link rel="prefetch" href="/assets/index.html-78e1edef.js" as="script"><link rel="prefetch" href="/assets/index.html-95c6778e.js" as="script"><link rel="prefetch" href="/assets/index.html-ef15ab18.js" as="script"><link rel="prefetch" href="/assets/index.html-de15c52f.js" as="script"><link rel="prefetch" href="/assets/index.html-3ffa64a8.js" as="script"><link rel="prefetch" href="/assets/index.html-0c4ebc78.js" as="script"><link rel="prefetch" href="/assets/index.html-7c39f58a.js" as="script"><link rel="prefetch" href="/assets/index.html-dc0cfaa1.js" as="script"><link rel="prefetch" href="/assets/index.html-e6f556de.js" as="script"><link rel="prefetch" href="/assets/index.html-996c738c.js" as="script"><link rel="prefetch" href="/assets/index.html-946da1ee.js" as="script"><link rel="prefetch" href="/assets/index.html-30e4e921.js" as="script"><link rel="prefetch" href="/assets/index.html-e2a85053.js" as="script"><link rel="prefetch" href="/assets/index.html-41d7be7d.js" as="script"><link rel="prefetch" href="/assets/index.html-36154924.js" as="script"><link rel="prefetch" href="/assets/index.html-334a54b6.js" as="script"><link rel="prefetch" href="/assets/index.html-2ae1afae.js" as="script"><link rel="prefetch" href="/assets/index.html-0c3db965.js" as="script"><link rel="prefetch" href="/assets/index.html-6b1ed3d2.js" as="script"><link rel="prefetch" href="/assets/index.html-4e97df2f.js" as="script"><link rel="prefetch" href="/assets/index.html-35e6c463.js" as="script"><link rel="prefetch" href="/assets/intro.html-6819bfce.js" as="script"><link rel="prefetch" href="/assets/slides.html-a56eba36.js" as="script"><link rel="prefetch" href="/assets/202309.html-d662fce6.js" as="script"><link rel="prefetch" href="/assets/202310.html-52ce4747.js" as="script"><link rel="prefetch" href="/assets/maoxuan.html-05125f75.js" as="script"><link rel="prefetch" href="/assets/index.html-f3d1f7d5.js" as="script"><link rel="prefetch" href="/assets/disable.html-b53c8bd3.js" as="script"><link rel="prefetch" href="/assets/encrypt.html-86ef3ea1.js" as="script"><link rel="prefetch" href="/assets/markdown.html-359a9462.js" as="script"><link rel="prefetch" href="/assets/page.html-9aab3ec7.js" as="script"><link rel="prefetch" href="/assets/index.html-eccba7b4.js" as="script"><link rel="prefetch" href="/assets/dialog.html-29c123dd.js" as="script"><link rel="prefetch" href="/assets/video.html-485df62a.js" as="script"><link rel="prefetch" href="/assets/index.html-ffe892c3.js" as="script"><link rel="prefetch" href="/assets/index.html-4c552126.js" as="script"><link rel="prefetch" href="/assets/markdown01.html-ab5e34dd.js" as="script"><link rel="prefetch" href="/assets/markdown02.html-14cddb1f.js" as="script"><link rel="prefetch" href="/assets/index.html-9cb56192.js" as="script"><link rel="prefetch" href="/assets/contrastiveLearning.html-ccb25ae8.js" as="script"><link rel="prefetch" href="/assets/multiModal.html-47d7bcc5.js" as="script"><link rel="prefetch" href="/assets/videoRepresentation.html-5d8c7ec0.js" as="script"><link rel="prefetch" href="/assets/videoUnderstanding.html-918c9bf1.js" as="script"><link rel="prefetch" href="/assets/Bloodborne.html-87b56b60.js" as="script"><link rel="prefetch" href="/assets/DeathStranding.html-f76e1dc9.js" as="script"><link rel="prefetch" href="/assets/AVSD.html-7672daec.js" as="script"><link rel="prefetch" href="/assets/DDP.html-f2a8ec1b.js" as="script"><link rel="prefetch" href="/assets/trick.html-8962171f.js" as="script"><link rel="prefetch" href="/assets/index.html-c526b276.js" as="script"><link rel="prefetch" href="/assets/manual01.html-98d4e4e0.js" as="script"><link rel="prefetch" href="/assets/manual02.html-258308a3.js" as="script"><link rel="prefetch" href="/assets/manual03.html-8d615856.js" as="script"><link rel="prefetch" href="/assets/index.html-6f9daecd.js" as="script"><link rel="prefetch" href="/assets/documentnotes01.html-661a4336.js" as="script"><link rel="prefetch" href="/assets/documentnotes02.html-a4f25d10.js" as="script"><link rel="prefetch" href="/assets/documentnotes03.html-7bfe7168.js" as="script"><link rel="prefetch" href="/assets/documentnotes04.html-eb624d9c.js" as="script"><link rel="prefetch" href="/assets/documentnotes05.html-30c4e30e.js" as="script"><link rel="prefetch" href="/assets/documentnotes06.html-ea6caf45.js" as="script"><link rel="prefetch" href="/assets/documentnotes07.html-724e5507.js" as="script"><link rel="prefetch" href="/assets/documentnotes08.html-dbedd2ad.js" as="script"><link rel="prefetch" href="/assets/documentnotes09.html-4f2bb3ae.js" as="script"><link rel="prefetch" href="/assets/documentnotes10.html-5c0638be.js" as="script"><link rel="prefetch" href="/assets/documentnotes11.html-cec06dac.js" as="script"><link rel="prefetch" href="/assets/404.html-2444edfe.js" as="script"><link rel="prefetch" href="/assets/index.html-69fcdd68.js" as="script"><link rel="prefetch" href="/assets/index.html-5615a7cb.js" as="script"><link rel="prefetch" href="/assets/index.html-79dc60d8.js" as="script"><link rel="prefetch" href="/assets/index.html-6072e888.js" as="script"><link rel="prefetch" href="/assets/index.html-4f2e4f66.js" as="script"><link rel="prefetch" href="/assets/index.html-0ab11eb2.js" as="script"><link rel="prefetch" href="/assets/index.html-f0bf0bac.js" as="script"><link rel="prefetch" href="/assets/index.html-531e0b94.js" as="script"><link rel="prefetch" href="/assets/index.html-6a44025d.js" as="script"><link rel="prefetch" href="/assets/index.html-353b30ae.js" as="script"><link rel="prefetch" href="/assets/index.html-36fb8225.js" as="script"><link rel="prefetch" href="/assets/index.html-b1ee8d72.js" as="script"><link rel="prefetch" href="/assets/index.html-59199612.js" as="script"><link rel="prefetch" href="/assets/index.html-dcd6e28d.js" as="script"><link rel="prefetch" href="/assets/index.html-5e9d3582.js" as="script"><link rel="prefetch" href="/assets/index.html-91adf916.js" as="script"><link rel="prefetch" href="/assets/index.html-85aec8e1.js" as="script"><link rel="prefetch" href="/assets/index.html-e19d1f60.js" as="script"><link rel="prefetch" href="/assets/index.html-1f8628f5.js" as="script"><link rel="prefetch" href="/assets/index.html-a7885530.js" as="script"><link rel="prefetch" href="/assets/index.html-cab142c2.js" as="script"><link rel="prefetch" href="/assets/index.html-29fd0c6c.js" as="script"><link rel="prefetch" href="/assets/index.html-ea209a65.js" as="script"><link rel="prefetch" href="/assets/index.html-9c84cdd5.js" as="script"><link rel="prefetch" href="/assets/index.html-3c03f680.js" as="script"><link rel="prefetch" href="/assets/index.html-5cdc58f9.js" as="script"><link rel="prefetch" href="/assets/index.html-66dbef88.js" as="script"><link rel="prefetch" href="/assets/index.html-c9ef454a.js" as="script"><link rel="prefetch" href="/assets/index.html-3dd7bd71.js" as="script"><link rel="prefetch" href="/assets/index.html-89738ff3.js" as="script"><link rel="prefetch" href="/assets/index.html-e8a48cc1.js" as="script"><link rel="prefetch" href="/assets/index.html-fcdb3ae9.js" as="script"><link rel="prefetch" href="/assets/index.html-e07ee93d.js" as="script"><link rel="prefetch" href="/assets/index.html-6fb3c21f.js" as="script"><link rel="prefetch" href="/assets/index.html-69079aba.js" as="script"><link rel="prefetch" href="/assets/index.html-e500e0d6.js" as="script"><link rel="prefetch" href="/assets/index.html-4d33bf08.js" as="script"><link rel="prefetch" href="/assets/index.html-6047854f.js" as="script"><link rel="prefetch" href="/assets/index.html-138aebd1.js" as="script"><link rel="prefetch" href="/assets/index.html-3f9304e1.js" as="script"><link rel="prefetch" href="/assets/index.html-99b36838.js" as="script"><link rel="prefetch" href="/assets/auto-fe80bb03.js" as="script"><link rel="prefetch" href="/assets/index-2bf332f6.js" as="script"><link rel="prefetch" href="/assets/flowchart-c441f34d.js" as="script"><link rel="prefetch" href="/assets/mermaid.core-72b25d9c.js" as="script"><link rel="prefetch" href="/assets/highlight.esm-75b11b9d.js" as="script"><link rel="prefetch" href="/assets/markdown.esm-9d5bc2ce.js" as="script"><link rel="prefetch" href="/assets/math.esm-70a288c8.js" as="script"><link rel="prefetch" href="/assets/notes.esm-a106bb2c.js" as="script"><link rel="prefetch" href="/assets/reveal.esm-1a4c3ae7.js" as="script"><link rel="prefetch" href="/assets/search.esm-7e6792e2.js" as="script"><link rel="prefetch" href="/assets/zoom.esm-b83b91d0.js" as="script"><link rel="prefetch" href="/assets/VuePlayground-1b9d15fa.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-5762295a.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="vp-link vp-brand vp-brand" href="/"><img class="vp-nav-logo" src="/logo.svg" alt=" "><!----><span class="vp-site-name hide-in-pad"> </span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="🔧 工具"><span class="title"><!---->🔧 工具</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><h4 class="dropdown-subtitle"><span>文档</span></h4><ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a aria-label="Markdown" class="vp-link nav-link nav-link" href="/Tools/MarkDown.html"><!---->Markdown<!----></a></li><li class="dropdown-subitem"><a aria-label="资源整合" class="vp-link nav-link nav-link" href="/Tools/Resource.html"><!---->资源整合<!----></a></li></ul></li><li class="dropdown-item"><h4 class="dropdown-subtitle"><span>工具</span></h4><ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a aria-label="Git" class="vp-link nav-link nav-link" href="/Tools/Git.html"><!---->Git<!----></a></li></ul></li></ul></button></div></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="  📑 码头"><span class="title"><!---->  📑 码头</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a aria-label="视频理解" class="vp-link nav-link nav-link" href="/keyan/videoUnderstanding/videoUnderstanding.html"><!---->视频理解<!----></a></li><li class="dropdown-item"><a aria-label="视频表征" class="vp-link nav-link nav-link" href="/keyan/videoRepresentation/videoRepresentation.html"><!---->视频表征<!----></a></li><li class="dropdown-item"><a aria-label="视频对话" class="vp-link nav-link active nav-link active" href="/keyan/videoDialog/videoDialog.html"><!---->视频对话<!----></a></li><li class="dropdown-item"><a aria-label="对比学习" class="vp-link nav-link nav-link" href="/keyan/contrastiveLearning/contrastiveLearning.html"><!---->对比学习<!----></a></li><li class="dropdown-item"><a aria-label="多模态" class="vp-link nav-link nav-link" href="/keyan/multiModal/multiModal.html"><!---->多模态<!----></a></li></ul></button></div></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="  🧫 炉"><span class="title"><!---->  🧫 炉</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a aria-label="单机多卡DDP" class="vp-link nav-link nav-link" href="/train/DDP/DDP.html"><!---->单机多卡DDP<!----></a></li><li class="dropdown-item"><a aria-label="AVSD" class="vp-link nav-link nav-link" href="/train/AVSD/AVSD.html"><!---->AVSD<!----></a></li><li class="dropdown-item"><a aria-label="奇淫技巧" class="vp-link nav-link nav-link" href="/train/trick/trick.html"><!---->奇淫技巧<!----></a></li></ul></button></div></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="  📖 道心"><span class="title"><!---->  📖 道心</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a aria-label="2023年9月" class="vp-link nav-link nav-link" href="/book/202309.html"><!---->2023年9月<!----></a></li><li class="dropdown-item"><a aria-label="2023年10月" class="vp-link nav-link nav-link" href="/book/202310.html"><!---->2023年10月<!----></a></li><li class="dropdown-item"><a aria-label="毛泽东选集" class="vp-link nav-link nav-link" href="/book/maoxuan.html"><!---->毛泽东选集<!----></a></li></ul></button></div></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><!----><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://github.com/vuepress-theme-hope/vuepress-theme-hope" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button type="button" id="appearance-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!----><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"><li><!--[--><a aria-label="视频理解综述性质的记录" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/keyan/videoUnderstanding/videoUnderstanding.html"><!---->视频理解综述性质的记录<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="关于视频理解的论文收集(较新)" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/keyan/videoRepresentation/videoRepresentation.html"><!---->关于视频理解的论文收集(较新)<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="视频对话方向大论文性质的记录" class="vp-link nav-link active vp-sidebar-link vp-sidebar-page active nav-link active vp-sidebar-link vp-sidebar-page active" href="/keyan/videoDialog/videoDialog.html"><!---->视频对话方向大论文性质的记录<!----></a><ul class="vp-sidebar-sub-headers"><li class="vp-sidebar-sub-header"><a aria-label="Information-Theoretic Text Hallucination Reduction for Video-grounded Dialogue" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/keyan/videoDialog/videoDialog.html#information-theoretic-text-hallucination-reduction-for-video-grounded-dialogue"><!---->Information-Theoretic Text Hallucination Reduction for Video-grounded Dialogue<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="Video Dialog as Conversation about Objects Living in Space-Time" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/keyan/videoDialog/videoDialog.html#video-dialog-as-conversation-about-objects-living-in-space-time"><!---->Video Dialog as Conversation about Objects Living in Space-Time<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="Structured Co-reference Graph Attention for Video-grounded Dialogue" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/keyan/videoDialog/videoDialog.html#structured-co-reference-graph-attention-for-video-grounded-dialogue"><!---->Structured Co-reference Graph Attention for Video-grounded Dialogue<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="BiST: Bi-directional Spatio-Temporal Reasoning for Video-Grounded Dialogues" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/keyan/videoDialog/videoDialog.html#bist-bi-directional-spatio-temporal-reasoning-for-video-grounded-dialogues"><!---->BiST: Bi-directional Spatio-Temporal Reasoning for Video-Grounded Dialogues<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="Describing Unseen Videos via Multi-Modal Cooperative Dialog Agents" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/keyan/videoDialog/videoDialog.html#describing-unseen-videos-via-multi-modal-cooperative-dialog-agents"><!---->Describing Unseen Videos via Multi-Modal Cooperative Dialog Agents<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="Dynamic Graph Representation Learning for Video Dialog via Multi-Modal Shuffled Transformers" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/keyan/videoDialog/videoDialog.html#dynamic-graph-representation-learning-for-video-dialog-via-multi-modal-shuffled-transformers"><!---->Dynamic Graph Representation Learning for Video Dialog via Multi-Modal Shuffled Transformers<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="Video-Grounded Dialogues with Pretrained Generation Language Models" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/keyan/videoDialog/videoDialog.html#video-grounded-dialogues-with-pretrained-generation-language-models"><!---->Video-Grounded Dialogues with Pretrained Generation Language Models<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="Multi-Speaker Video Dialog with Frame-Level Temporal Localization" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/keyan/videoDialog/videoDialog.html#multi-speaker-video-dialog-with-frame-level-temporal-localization"><!---->Multi-Speaker Video Dialog with Frame-Level Temporal Localization<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="Multimodal Transformer Networks for End-to-End Video-Grounded Dialogue Systems" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/keyan/videoDialog/videoDialog.html#multimodal-transformer-networks-for-end-to-end-video-grounded-dialogue-systems"><!---->Multimodal Transformer Networks for End-to-End Video-Grounded Dialogue Systems<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a aria-label="Video Dialog via Progressive Inference and Cross-Transformer" class="vp-link nav-link vp-sidebar-link vp-heading nav-link vp-sidebar-link vp-heading" href="/keyan/videoDialog/videoDialog.html#video-dialog-via-progressive-inference-and-cross-transformer"><!---->Video Dialog via Progressive Inference and Cross-Transformer<!----></a><ul class="vp-sidebar-sub-headers"></ul></li></ul><!--]--></li><li><!--[--><a aria-label="对比学习综述性质的记录" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/keyan/contrastiveLearning/contrastiveLearning.html"><!---->对比学习综述性质的记录<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a aria-label="多模态方向综述性质的记录" class="vp-link nav-link vp-sidebar-link vp-sidebar-page nav-link vp-sidebar-link vp-sidebar-page" href="/keyan/multiModal/multiModal.html"><!---->多模态方向综述性质的记录<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->视频对话方向大论文性质的记录</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="https://github.com/WillebrordSnell" target="_blank" rel="noopener noreferrer">Mr.R</a></span><span property="author" content="Mr.R"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2023-10-26T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 3 分钟</span><meta property="timeRequired" content="PT3M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category0 clickable" role="navigation">码头</span><!--]--><meta property="articleSection" content="码头"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag5 clickable" role="navigation">视频对话</span><!--]--><meta property="keywords" content="视频对话"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">此页内容<button type="button" class="print-button" title="打印"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#information-theoretic-text-hallucination-reduction-for-video-grounded-dialogue">Information-Theoretic Text Hallucination Reduction for Video-grounded Dialogue</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#video-dialog-as-conversation-about-objects-living-in-space-time">Video Dialog as Conversation about Objects Living in Space-Time</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#structured-co-reference-graph-attention-for-video-grounded-dialogue">Structured Co-reference Graph Attention for Video-grounded Dialogue</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#bist-bi-directional-spatio-temporal-reasoning-for-video-grounded-dialogues">BiST: Bi-directional Spatio-Temporal Reasoning for Video-Grounded Dialogues</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#describing-unseen-videos-via-multi-modal-cooperative-dialog-agents">Describing Unseen Videos via Multi-Modal Cooperative Dialog Agents</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#dynamic-graph-representation-learning-for-video-dialog-via-multi-modal-shuffled-transformers">Dynamic Graph Representation Learning for Video Dialog via Multi-Modal Shuffled Transformers</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#video-grounded-dialogues-with-pretrained-generation-language-models">Video-Grounded Dialogues with Pretrained Generation Language Models</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#multi-speaker-video-dialog-with-frame-level-temporal-localization">Multi-Speaker Video Dialog with Frame-Level Temporal Localization</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#multimodal-transformer-networks-for-end-to-end-video-grounded-dialogue-systems">Multimodal Transformer Networks for End-to-End Video-Grounded Dialogue Systems</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2 toc-link level2" href="/#video-dialog-via-progressive-inference-and-cross-transformer">Video Dialog via Progressive Inference and Cross-Transformer</a></li><!----><!--]--></ul><div class="toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!----><div class="theme-hope-content"><h1 id="视频对话方向大论文性质的记录" tabindex="-1"><a class="header-anchor" href="#视频对话方向大论文性质的记录" aria-hidden="true">#</a> 视频对话方向大论文性质的记录</h1><p>视频对话领域在近几年顶刊上的paper寥寥无几并且在大模型的冲击下许多工作其本质就是换皮，本无打算特地做综述性质的报告，但由于开题和毕业论文需要，故留记录</p><h2 id="information-theoretic-text-hallucination-reduction-for-video-grounded-dialogue" tabindex="-1"><a class="header-anchor" href="#information-theoretic-text-hallucination-reduction-for-video-grounded-dialogue" aria-hidden="true">#</a> Information-Theoretic Text Hallucination Reduction for Video-grounded Dialogue</h2><blockquote><p>论文地址：<a href="https://arxiv.org/abs/2212.05765" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2212.05765<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><p>本文提出AVSD中存在：不理解问题的情况下不加区分地抄袭输入文本，其原因是由于数据集中的答案句子通常包含输入文本中的单词，因此VGD(Video-grounded Dialogue)系统过度依赖于复制输入文本中的单词，希望这些单词与地面实况文本重叠，从而学习到虚假的相关性。</p><h2 id="video-dialog-as-conversation-about-objects-living-in-space-time" tabindex="-1"><a class="header-anchor" href="#video-dialog-as-conversation-about-objects-living-in-space-time" aria-hidden="true">#</a> Video Dialog as Conversation about Objects Living in Space-Time</h2><blockquote><p>论文地址：<a href="https://arxiv.org/abs/2207.03656" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2207.03656<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><p>本文认为：对话的自然流程是多次转折，每次转折都建立在之前的问答基础之上。这就要求在语言上深刻理解和跟踪已经说过的话，并以视频中的视觉概念为基础，然后在新建立的语境中分析新问题。其难点主要体现在 场景的时间动态性</p><h2 id="structured-co-reference-graph-attention-for-video-grounded-dialogue" tabindex="-1"><a class="header-anchor" href="#structured-co-reference-graph-attention-for-video-grounded-dialogue" aria-hidden="true">#</a> Structured Co-reference Graph Attention for Video-grounded Dialogue</h2><blockquote><p>论文地址：<a href="https://arxiv.org/abs/2103.13361" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2103.13361<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><p>本文认为视频对话难点在于：(1) 如何推断多种模态之间的共同参照(包含文本中的指代消解问题)；(2) 如何推理具有复杂时空动态的视频的丰富底层语义结构。</p><h2 id="bist-bi-directional-spatio-temporal-reasoning-for-video-grounded-dialogues" tabindex="-1"><a class="header-anchor" href="#bist-bi-directional-spatio-temporal-reasoning-for-video-grounded-dialogues" aria-hidden="true">#</a> BiST: Bi-directional Spatio-Temporal Reasoning for Video-Grounded Dialogues</h2><blockquote><p>论文地址：<a href="https://arxiv.org/abs/2010.10095" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2010.10095<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><p>本文认为AVSD：(i) 包含空间和时间变化的视频的复杂性，以及 (ii) 在多个对话回合中查询视频中不同片段和/或不同对象的用户话语的复杂性。并且此前的方法都认为空间中所有的object都是一样重要，但其实并不是所有object对于当前问题有同样的贡献度</p><h2 id="describing-unseen-videos-via-multi-modal-cooperative-dialog-agents" tabindex="-1"><a class="header-anchor" href="#describing-unseen-videos-via-multi-modal-cooperative-dialog-agents" aria-hidden="true">#</a> Describing Unseen Videos via Multi-Modal Cooperative Dialog Agents</h2><blockquote><p>论文地址：<a href="https://arxiv.org/abs/2008.07935" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2008.07935<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><p>参考意义不大</p><h2 id="dynamic-graph-representation-learning-for-video-dialog-via-multi-modal-shuffled-transformers" tabindex="-1"><a class="header-anchor" href="#dynamic-graph-representation-learning-for-video-dialog-via-multi-modal-shuffled-transformers" aria-hidden="true">#</a> Dynamic Graph Representation Learning for Video Dialog via Multi-Modal Shuffled Transformers</h2><blockquote><p>论文地址：<a href="https://arxiv.org/abs/2007.03848" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2007.03848<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><p>本文是早期(2020)的paper，因此在那个连多模态融合都没有做好的年代其主要难点自然就是如何融合多模态信息了</p><h2 id="video-grounded-dialogues-with-pretrained-generation-language-models" tabindex="-1"><a class="header-anchor" href="#video-grounded-dialogues-with-pretrained-generation-language-models" aria-hidden="true">#</a> Video-Grounded Dialogues with Pretrained Generation Language Models</h2><blockquote><p>论文地址：<a href="https://arxiv.org/abs/2006.15319" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2006.15319<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><p>本文只是把GTP2放在AVSD数据集上做了fine tune，严重怀疑最后的预测其实根本就没用到输入的视频信息</p><h2 id="multi-speaker-video-dialog-with-frame-level-temporal-localization" tabindex="-1"><a class="header-anchor" href="#multi-speaker-video-dialog-with-frame-level-temporal-localization" aria-hidden="true">#</a> Multi-Speaker Video Dialog with Frame-Level Temporal Localization</h2><blockquote><p>论文地址：<a href="https://ojs.aaai.org/index.php/AAAI/article/view/6901" target="_blank" rel="noopener noreferrer">https://ojs.aaai.org/index.php/AAAI/article/view/6901<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><p>本文提到在实际应用中，准确定位对应的视频子段始终是很困难的。其意思应该和我思路差不多，通过增加一个视频定位模块做模型的可解释性部分，并且也许能带来性能的提升。(艹 又被做了)</p><h2 id="multimodal-transformer-networks-for-end-to-end-video-grounded-dialogue-systems" tabindex="-1"><a class="header-anchor" href="#multimodal-transformer-networks-for-end-to-end-video-grounded-dialogue-systems" aria-hidden="true">#</a> Multimodal Transformer Networks for End-to-End Video-Grounded Dialogue Systems</h2><blockquote><p>论文地址：<a href="https://arxiv.org/abs/1907.01166" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/1907.01166<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><p>本文也是AVSD领域的早期(2019)工作，其中提出的问题比较基础：(1) 由于跨多个视频帧的背景噪声、人类语音、动作流等信息多种多样，视频的特征空间比基于文本或基于图像的特征更大、更复杂； (2) 会话代理必须能够感知和理解来自不同模式的信息（来自对话历史和人类查询的文本、来自视频的视觉和音频特征），并在语义上形成对人类有意义的响应。</p><h2 id="video-dialog-via-progressive-inference-and-cross-transformer" tabindex="-1"><a class="header-anchor" href="#video-dialog-via-progressive-inference-and-cross-transformer" aria-hidden="true">#</a> Video Dialog via Progressive Inference and Cross-Transformer</h2><blockquote><p>论文地址：<a href="https://aclanthology.org/D19-1217/" target="_blank" rel="noopener noreferrer">https://aclanthology.org/D19-1217/<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><p>transform战士，用transform结构代替RNN在AVSD的位置</p></div><!----><footer class="page-meta"><div class="meta-item edit-link"><a href="https://github.com/vuepress-theme-hope/vuepress-theme-hope/edit/main/src/keyan/videoDialog/_videoDialog.md" rel="noopener noreferrer" target="_blank" aria-label="在 GitHub 上编辑此页" class="nav-link label"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->在 GitHub 上编辑此页<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!----></a></div><div class="meta-item git-info"><div class="update-time"><span class="label">上次编辑于: </span><!----></div><div class="contributors"><span class="label">贡献者: </span><!--[--><!--[--><span class="contributor" title="email: 799976781@qq.com">WillebrordSnell</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><a aria-label="关于视频理解的论文收集(较新)" class="vp-link nav-link prev nav-link prev" href="/keyan/videoRepresentation/videoRepresentation.html"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><!---->关于视频理解的论文收集(较新)</div></a><a aria-label="对比学习综述性质的记录" class="vp-link nav-link next nav-link next" href="/keyan/contrastiveLearning/contrastiveLearning.html"><div class="hint">下一页<span class="arrow end"></span></div><div class="link">对比学习综述性质的记录<!----></div></a></nav><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer">西湖美景, 三月天嘞~</div><div class="vp-copyright">Copyright © 2023 Mr.R</div></footer></div><!--]--><!----><!--]--></div>
    <script type="module" src="/assets/app-cab84357.js" defer></script>
  </body>
</html>
