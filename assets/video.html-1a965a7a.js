import{_ as e}from"./plugin-vue_export-helper-c27b6911.js";import{o as i,c as o,f as n}from"./app-1d4c5d3b.js";const r={},t=n('<h1 id="一些关于video方向的论文收集" tabindex="-1"><a class="header-anchor" href="#一些关于video方向的论文收集" aria-hidden="true">#</a> 一些关于video方向的论文收集</h1><p>本文主要记录一下近4年(2019年起)各顶会顶刊有关video的paper名字，以便后续video dialog工作的调研和展开<br> (本文档未经过任何筛选，仅通过关键词搜索得到paper名字)</p><h3 id="_2022-eccv" tabindex="-1"><a class="header-anchor" href="#_2022-eccv" aria-hidden="true">#</a> 2022 ECCV</h3><p>DexMV: Imitation Learning for Dexterous Manipulation from Human Videos<br> Video Dialog as Conversation About Objects Living in Space-Time<br> Actor-Centered Representations for Action Localization in Streaming Videos<br> AutoTransition: Learning to Recommend Video Transition Effects<br> Sports Video Analysis on Large-Scale Data<br> Semantic-Aware Implicit Neural Audio-Driven Video Portrait Generation<br> Quantized GAN for Complex Music Generation from Dance Videos<br> Telepresence Video Quality Assessment<br> GAMa: Cross-View Video Geo-Localization<br> FAR: Fourier Aerial Video Recognition<br> Fabric Material Recovery from Video Using Multi-scale Geometric Auto-Encoder<br> Video Graph Transformer for Video Question Answering<br> Video Question Answering with Iterative Video-Text Co-tokenization<br> Can Shuffling Video Benefit Temporal Bias Problem: A Novel Training Framework for Temporal Grounding<br> Selective Query-Guided Debiasing for Video Corpus Moment Retrieval<br> Learning Linguistic Association Towards Efficient Text-Video Retrieval<br> VisageSynTalk: Unseen Speaker Video-to-Speech Synthesis via Speech-Visage Feature Selection<br> CycDA: Unsupervised Cycle Domain Adaptation to Learn from Image to Video<br> Expanding Language-Image Pretrained Models for General Video Recognition<br> AdaFocusV3: On Unified Spatial-Temporal Dynamic Video Recognition<br> Delving into Details: Synopsis-to-Detail Networks for Video Recognition<br> Scale-Aware Spatio-Temporal Relation Learning for Video Anomaly Detection<br> Continual 3D Convolutional Neural Networks for Real-time Processing of Videos<br> Geometric Features Informed Multi-person Human-Object Interaction Recognition in Videos<br> Neural Capture of Animatable 3D Human from Monocular Video<br> FAST-VQA: Efficient End-to-End Video Quality Assessment with Fragment Sampling<br> Real-RawVSR: Real-World Raw Video Super-Resolution with a Benchmark Dataset<br> Synthesizing Light Field Video from Monocular Video<br> Video Interpolation by Event-Driven Anisotropic Adjustment of Optical Flow<br> CelebV-HQ: A Large-Scale Video Facial Attributes Dataset<br> SmoothNet: A Plug-and-Play Network for Refining Human Poses in Videos<br> RayTran: 3D Pose Estimation and Shape Reconstruction of Multiple Objects from Videos with Ray-Traced Transformers<br> SALISA: Saliency-Based Input Sampling for Efficient Video Object Detection<br> Video Anomaly Detection by Solving Decoupled Spatio-Temporal Jigsaw Puzzles<br> Weakly-Supervised Temporal Action Detection for Fine-Grained Videos with Hierarchical Atomic Actions<br> Contrast-Phys: Unsupervised Video-Based Remote Physiological Measurement via Spatiotemporal Contrast<br> Hierarchical Contrastive Inconsistency Learning for Deepfake Video Detection<br> Generative Adversarial Network for Future Hand Segmentation from Egocentric Video<br> My View is the Best View: Procedure Learning from Egocentric Videos<br> Self-supervised Sparse Representation for Video Anomaly Detection<br> Few-Shot Video Object Detection<br> Inductive and Transductive Few-Shot Video Classification via Appearance and Temporal Alignments<br> Graph Neural Network for Cell Tracking in Microscopy Videos<br> Particle Video Revisited: Tracking Through Occlusions Using Point Trajectories<br> Towards Generic 3D Tracking in RGBD Videos: Benchmark and Baseline<br> Tackling Background Distraction in Video Object Segmentation<br> Learned Variational Video Color Propagation<br> Ensemble Learning Priors Driven Deep Unfolding for Scalable Video Snapshot Compressive Imaging<br> Bridging Images and Videos: A Simple Learning Framework for Large Vocabulary Video Object Detection<br> LocVTP: Video-Text Pre-training for Temporal Localization<br> Learning to Drive by Watching YouTube Videos: Action-Conditioned Contrastive Policy Pretraining<br> Static and Dynamic Concepts for Self-supervised Video Representation Learning<br> Neural Video Compression Using GANs for Detail Synthesis and Propagation<br> Is It Necessary to Transfer Temporal Knowledge for Domain Adaptive Video Semantic Segmentation?<br> Meta Spatio-Temporal Debiasing for Video Scene Graph Generation<br> PolyphonicFormer: Unified Query Learning for Depth-Aware Video Panoptic Segmentation<br> Video Restoration Framework and Its Meta-adaptations to Data-Poor Conditions<br> SeqFormer: Sequential Transformer for Video Instance Segmentation<br> In Defense of Online Models for Video Instance Segmentation<br> XMem: Long-Term Video Object Segmentation with an Atkinson-Shiffrin Memory Model<br> Video Mask Transfiner for High-Quality Video Instance Segmentation<br> Point Primitive Transformer for Long-Term 4D Point Cloud Video Understanding<br> Waymo Open Dataset: Panoramic Video Panoptic Segmentation<br> One-Trimap Video Matting<br> Learning Quality-aware Dynamic Memory for Video Object Segmentation<br> Instance as Identity: A Generic Online Paradigm for Video Instance Segmentation<br> BATMAN: Bilateral Attention Transformer in Motion-Appearance Neighboring Space for Video Object Segmentation<br> Global Spectral Filter Memory Network for Video Object Segmentation<br> Video Instance Segmentation via Multi-Scale Spatio-Temporal Split Attention Transformer<br> Domain Adaptive Video Segmentation via Temporal Pseudo Supervision<br> GOCA: Guided Online Cluster Assignment for Self-supervised Video Representation Learning<br> Learn2Augment: Learning to Composite Videos for Data Augmentation in Action Recognition<br> Federated Self-supervised Learning for Video Understanding<br> NeuMan: Neural Human Radiance Field from a Single Video<br> Structure and Motion from Casual Videos<br> The Anatomy of Video Editing: A Dataset and Benchmark Suite for AI-Assisted Video Editing<br> MUGEN: A Playground for Video-Audio-Text Multimodal Understanding and GENeration<br> earning Omnidirectional Flow in 360$^\\circ $ Video via Siamese Representation<br> PTSEFormer: Progressive Temporal-Spatial Enhanced TransFormer Towards Video Object Detection<br> Dual-Stream Knowledge-Preserving Hashing for Unsupervised Video Retrieval<br> Multi-query Video Retrieval<br> TS2-Net: Token Shift and Selection Transformer for Text-Video Retrieval<br> Learning Audio-Video Modalities from Image Captions<br> Lightweight Attentional Feature Fusion: A New Baseline for Text-to-Video Retrieval<br> Audio-Visual Mismatch-Aware Video Retrieval via Association and Adjustment<br> CAViT: Contextual Alignment Vision Transformer for Video Object Re-identification<br> Relighting4D: Neural Relightable Human from Videos<br> Real-Time Intermediate Flow Estimation for Video Frame Interpolation<br> Deep Bayesian Video Frame Interpolation<br> A Perceptual Quality Metric for Video Frame Interpolation<br> Fast-Vid2Vid: Spatial-Temporal Compression for Video-to-Video Synthesis<br> Temporally Consistent Semantic Video Editing<br> Error Compensation Framework for Flow-Guided Video Inpainting<br> Learning Cross-Video Neural Representations for High-Quality Frame Interpolation<br> A Style-Based GAN Encoder for High Fidelity Reconstruction of Images and Videos<br> Harmonizer: Learning to Perform White-Box Image and Video Harmonization<br> Text2LIVE: Text-Driven Layered Image and Video Editing<br> CANF-VC: Conditional Augmented Normalizing Flows for Video Compression<br> Video Extrapolation in Space and Time<br> Augmentation of rPPG Benchmark Datasets: Learning to Remove and Embed rPPG Signals via Double Cycle Consistent Learning from Unpaired Facial Videos<br> Layered Controllable Video Generation<br> Spatio-Temporal Deformable Attention Network for Video Deblurring<br> Sound-Guided Semantic Video Generation<br> Controllable Video Generation Through Global and Local Motion Dynamics<br> Long Video Generation with Time-Agnostic VQGAN and Time-Sensitive Transformer<br> Combining Internal and External Constraints for Unrolling Shutter in Videos<br> A Codec Information Assisted Framework for Efficient Compressed Video Super-Resolution<br> Diverse Generation from a Single Video Made Possible<br> Learning Shadow Correspondence for Video Shadow Detection<br> Flow-Guided Transformer for Video Inpainting<br> Learning Spatio-Temporal Downsampling for Effective Video Upscaling<br> Learning Spatiotemporal Frequency-Transformer for Compressed Video Super-Resolution<br> Efficient Meta-Tuning for Content-Aware Neural Video Delivery<br> Towards Interpretable Video Super-Resolution via Alternating Optimization<br> Event-guided Deblurring of Unknown Exposure Time Videos<br> Unidirectional Video Denoising by Mimicking Backward Recurrent Modules with Look-Ahead Forward Ones<br> ERDN: Equivalent Receptive Field Deformable Network for Video Deblurring<br> RealFlow: EM-Based Realistic Optical Flow Dataset Generation from Videos<br> Efficient Video Deblurring Guided by Motion Magnitude<br> TempFormer: Temporally Consistent Transformer for Video Denoising<br> Rethinking Video Rain Streak Removal: A New Synthesis Model and a Deraining Network with Video Rain Prior<br> AlphaVC: High-Performance and Efficient Learned Video Compression<br> Source-Free Video Domain Adaptation by Learning Temporal Consistency for Action Recognition<br> Towards Open Set Video Anomaly Detection<br> EclipSE: Efficient Long-Range Video Retrieval Using Sight and Sound<br> Joint-Modal Label Denoising for Weakly-Supervised Audio-Visual Video Parsing<br> Less Than Few: Self-shot Video Instance Segmentation<br> Real-Time Online Video Detection with Temporal Smoothing Transformers<br> Mining Relations Among Cross-Frame Affinities for Video Semantic Segmentation<br> TL;DW? Summarizing Instructional Videos with Task Relevance and Cross-Modal Saliency<br> DualFormer: Local-Global Stratified Transformer for Efficient Video Recognition<br> Hierarchical Feature Alignment Network for Unsupervised Video Object Segmentation<br> PAC-Net: Highlight Your Video via History Preference Modeling<br> How Severe Is Benchmark-Sensitivity in Video Self-supervised Learning?<br> NSNet: Non-saliency Suppression Sampler for Efficient Video Recognition<br> Video Activity Localisation with Uncertainties in Temporal Boundary<br> Temporal Saliency Query Network for Efficient Video Recognition<br> Efficient One-Stage Video Object Detection by Exploiting Temporal Consistency<br> Spotting Temporally Precise, Fine-Grained Events in Video<br> Efficient Video Transformers with Spatial-Temporal Token Selection<br> Long Movie Clip Classification with State-Space Video Models<br> Prompting Visual-Language Models for Efficient Video Understanding<br> Asymmetric Relation Consistency Reasoning for Video Relation Grounding<br> K-centered Patch Sampling for Efficient Video Recognition<br> GraphVid: It only Takes a Few Nodes to Understand a Video<br> Delta Distillation for Efficient Video Processing<br> COMPOSER: Compositional Reasoning of Group Activity in Videos with Keypoint-Only Modality<br> E-NeRV: Expedite Neural Video Representation with Disentangled Spatial-Temporal Context<br> TDViT: Temporal Dilated Video Transformer for Dense Video Tasks<br> Flow Graph to Video Grounding for Weakly-Supervised Multi-step Localization<br> MaCLR: Motion-Aware Contrastive Learning of Representations for Videos<br> Frozen CLIP Models are Efficient Video Learners<br> Panoramic Vision Transformer for Saliency Detection in 360$^\\circ $ Videos<br> Bayesian Tracking of Video Graphs Using Joint Kalman Smoothing and Registration<br> Motion Sensitive Contrastive Learning for Self-supervised Video Representation<br> Dynamic Temporal Filtering in Video Models<br> VTC: Improving Video-Text Retrieval with User Comments<br> Automatic Dense Annotation of Large-Vocabulary Sign Language Videos<br> MILES: Visual BERT Pre-training with Injected Language Semantics for Video-Text Retrieval</p><h3 id="_2020-eccv" tabindex="-1"><a class="header-anchor" href="#_2020-eccv" aria-hidden="true">#</a> 2020 ECCV</h3><p>Efficient Spatio-Temporal Recurrent Neural Network for Video Deblurring<br> CoTeRe-Net: Discovering Collaborative Ternary Relations in Videos<br> Visual Relation Grounding in Videos<br> SODA: Story Oriented Dense Video Captioning Evaluation Framework<br> Optical Flow Distillation: Towards Efficient and Stable Video Style Transfer<br> Learning Object Depth from Camera Motion and Video Object Segmentation<br> Localizing the Common Action Among a Few Videos<br> Two-Branch Recurrent Network for Isolating Deepfakes in Videos<br> World-Consistent Video-to-Video Synthesis<br> AttentionNAS: Spatiotemporal Attention Cell Search for Video Classification<br> Temporal Coherence or Temporal Motion: Which Is More Critical for Video-Based Person Re-identification?<br> Learning Event-Driven Video Deblurring and Interpolation<br> VPN: Learning Video-Pose Embedding for Activities of Daily Living<br> Joint Learning of Social Groups, Individuals Action and Sub-group Activities in Videos<br> Naive-Student: Leveraging Semi-Supervised Learning in Video Sequences for Urban Scene Segmentation<br> RhyRNN: Rhythmic RNN for Recognizing Events in Long and Complex Videos<br> MuCAN: Multi-correspondence Aggregation Network for Video Super-Resolution<br> Efficient Semantic Video Segmentation with Per-Frame Inference<br> TexMesh: Reconstructing Detailed Human Texture and Geometry from RGB-D Video<br> Deep Space-Time Video Upsampling Networks<br> Fast Video Object Segmentation Using the Global Context Module<br> Uncertainty-Aware Weakly Supervised Action Detection from Untrimmed Videos<br> STEm-Seg: Spatio-Temporal Embeddings for Instance Segmentation in Videos<br> Procedure Planning in Instructional Videos<br> Foley Music: Learning to Generate Music from Videos<br> Online Multi-modal Person Search in Videos<br> G-LBM: Generative Low-Dimensional Background Model Estimation from Video Sequences<br> Generating Videos of Zero-Shot Compositions of Actions and Objects<br> Video Super-Resolution with Recurrent Structure-Detail Network<br> Shuffle and Attend: Video Domain Adaptation<br> Flow-edge Guided Video Completion<br> Towards End-to-End Video-Based Eye-Tracking<br> Low Light Video Enhancement Using Synthetic Data Produced with an Intermediate Domain Mapping<br> ScribbleBox: Interactive Annotation Framework for Video Object Segmentation<br> MINI-Net: Multiple Instance Ranking Network for Video Highlight Detection<br> AutoTrajectory: Label-Free Trajectory Extraction and Prediction from Videos Using Dynamic Points<br> Motion Guided 3D Pose Estimation from Videos<br> SipMask: Spatial Information Preservation for Fast Image and Video Instance Segmentation<br> BMBC: Bilateral Motion Estimation with Bilateral Cost Volume for Video Interpolation<br> Video Object Detection via Object-Level Temporal Aggregation<br> READ: Reciprocal Attention Discriminator for Image-to-Video Re-identification<br> Multi-level Wavelet-Based Generative Adversarial Network for Perceptual Quality Enhancement of Compressed Video<br> Unsupervised Video Object Segmentation with Joint Hotspot Tracking<br> Memory Selection Network for Video Propagation<br> URVOS: Unified Referring Video Object Segmentation Network with a Large-Scale Benchmark<br> Clustering Driven Deep Autoencoder for Video Anomaly Detection<br> Omni-Sourced Webly-Supervised Learning for Video Recognition<br> Learning Where to Focus for Efficient Video Object Detection<br> Learning Object Permanence from Video<br> Temporal Aggregate Representations for Long-Range Video Understanding<br> Multimodal Memorability: Modeling Effects of Semantics and Decay on Video Memorability<br> MotionSqueeze: Neural Motion Feature Learning for Video Understanding<br> Learning Joint Spatial-Temporal Transformations for Video Inpainting<br> Probabilistic Future Prediction for Video Scene Understanding<br> Interactive Video Object Segmentation Using Global and Local Transfer Modules<br> Is Sharing of Egocentric Video Giving Away Your Biometric Signature?<br> Conditional Entropy Coding for Efficient Video Compression<br> Self-supervised Video Representation Learning by Pace Prediction<br> Self-supervised Multi-task Procedure Learning from Instructional Videos<br> Key Frame Proposal Network for Efficient Pose Estimation in Videos<br> We Have So Much in Common: Modeling Semantic Relational Set Abstractions in Videos<br> Self-supervised Learning of Audio-Visual Objects from Video<br> Knowledge-Based Video Question Answering with Unsupervised Scene Descriptions<br> RubiksNet: Learnable 3D-Shift for Efficient Video Action Recognition<br> Self-supervised Keypoint Correspondences for Multi-person Pose Estimation and Tracking in Videos<br> Motion-Excited Sampler: Video Adversarial Attack with Sparked Prior<br> DVI: Depth Guided Video Inpainting for Autonomous Driving<br> Adaptive Video Highlight Detection by Learning from User History<br> dentity-Aware Multi-sentence Video Description<br> Mining Inter-Video Proposal Relations for Video Object Detection<br> TVR: A Large-Scale Dataset for Video-Subtitle Moment Retrieval<br> Kernelized Memory Network for Video Object Segmentation<br> Disentangling Multiple Features in Video Sequences Using Gaussian Processes in Variational Autoencoders<br> Kinematic 3D Object Detection in Monocular Video<br> Describing Unseen Videos via Multi-modal Cooperative Dialog Agents<br> DeepLandscape: Adversarial Modeling of Landscape Videos<br> BIRNAT: Bidirectional Recurrent Neural Networks with Adversarial Training for Video Snapshot Compressive Imaging<br> Cross-Identity Motion Transfer for Arbitrary Objects Through Pose-Attentive Video Reassembling<br> Aligning Videos in Space and Time<br> Proposal-Based Video Completion<br> Exploiting Temporal Coherence for Self-Supervised One-Shot Video Re-identification<br> Multi-view Action Recognition Using Cross-View Video Prediction<br> Learning Discriminative Feature with CRF for Unsupervised Video Object Segmentation<br> VLANet: Video-Language Alignment Network for Weakly-Supervised Video Moment Retrieval<br> Video Representation Learning by Recognizing Temporal Transformations<br> Measuring the Importance of Temporal Features in Video Saliency<br> Representation Learning on Visual-Symbolic Graphs for Video Understanding<br> S3Net: Semantic-Aware Self-supervised Depth Estimation with Monocular Videos and Synthetic Data<br> High-Quality Single-Model Deep Video Compression with Frame-Conv3D and Multi-frame Differential Modulation</p><h3 id="_2021-iccv" tabindex="-1"><a class="header-anchor" href="#_2021-iccv" aria-hidden="true">#</a> 2021 ICCV</h3>',7),a=[t];function d(s,l){return i(),o("div",null,a)}const b=e(r,[["render",d],["__file","video.html.vue"]]);export{b as default};
