const e=JSON.parse('{"key":"v-55a252d4","path":"/keyan/videoRepresentation/videoRepresentation.html","title":"关于视频理解的论文收集(较新)","lang":"zh-CN","frontmatter":{"date":"2023-09-02T00:00:00.000Z","category":["码头"],"tag":["视频理解","视频对话"],"description":"关于视频理解的论文收集(较新) 本文可配合视频理解综述性质记录服用 Swin Transformer: Hierarchical Vision Transformer using Shifted Windows 论文地址：http://arxiv.org/abs/2103.14030 项目代码：https://github.com/microsoft/Swin-Transformer","head":[["meta",{"property":"og:url","content":"https://github.com/WillebrordSnell/keyan/videoRepresentation/videoRepresentation.html"}],["meta",{"property":"og:site_name","content":" "}],["meta",{"property":"og:title","content":"关于视频理解的论文收集(较新)"}],["meta",{"property":"og:description","content":"关于视频理解的论文收集(较新) 本文可配合视频理解综述性质记录服用 Swin Transformer: Hierarchical Vision Transformer using Shifted Windows 论文地址：http://arxiv.org/abs/2103.14030 项目代码：https://github.com/microsoft/Swin-Transformer"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2023-10-18T15:20:18.000Z"}],["meta",{"property":"article:author","content":"Mr.R"}],["meta",{"property":"article:tag","content":"视频理解"}],["meta",{"property":"article:tag","content":"视频对话"}],["meta",{"property":"article:published_time","content":"2023-09-02T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2023-10-18T15:20:18.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"关于视频理解的论文收集(较新)\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2023-09-02T00:00:00.000Z\\",\\"dateModified\\":\\"2023-10-18T15:20:18.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Mr.R\\",\\"url\\":\\"https://github.com/WillebrordSnell\\"}]}"]]},"headers":[{"level":2,"title":"Swin Transformer: Hierarchical Vision Transformer using Shifted Windows","slug":"swin-transformer-hierarchical-vision-transformer-using-shifted-windows","link":"#swin-transformer-hierarchical-vision-transformer-using-shifted-windows","children":[]},{"level":2,"title":"Is Space-Time Attention All You Need for Video Understanding?","slug":"is-space-time-attention-all-you-need-for-video-understanding","link":"#is-space-time-attention-all-you-need-for-video-understanding","children":[]},{"level":2,"title":"MViT: Multiscale Vision Transformers","slug":"mvit-multiscale-vision-transformers","link":"#mvit-multiscale-vision-transformers","children":[]},{"level":2,"title":"VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text","slug":"vatt-transformers-for-multimodal-self-supervised-learning-from-raw-video-audio-and-text","link":"#vatt-transformers-for-multimodal-self-supervised-learning-from-raw-video-audio-and-text","children":[]},{"level":2,"title":"SlowFast Networks for Video Recognition","slug":"slowfast-networks-for-video-recognition","link":"#slowfast-networks-for-video-recognition","children":[]},{"level":2,"title":"X3D: Expanding Architectures for Efficient Video Recognition","slug":"x3d-expanding-architectures-for-efficient-video-recognition","link":"#x3d-expanding-architectures-for-efficient-video-recognition","children":[]},{"level":2,"title":"Self-supervised Video Transformer","slug":"self-supervised-video-transformer","link":"#self-supervised-video-transformer","children":[]},{"level":2,"title":"With a Little Help from My Friends: Nearest-Neighbor Contrastive Learning of Visual Representations","slug":"with-a-little-help-from-my-friends-nearest-neighbor-contrastive-learning-of-visual-representations","link":"#with-a-little-help-from-my-friends-nearest-neighbor-contrastive-learning-of-visual-representations","children":[]},{"level":2,"title":"Solving Inefficiency of Self-supervised Representation Learning","slug":"solving-inefficiency-of-self-supervised-representation-learning","link":"#solving-inefficiency-of-self-supervised-representation-learning","children":[]},{"level":2,"title":"VideoMoCo: Contrastive Video Representation Learning with Temporally Adversarial Examples","slug":"videomoco-contrastive-video-representation-learning-with-temporally-adversarial-examples","link":"#videomoco-contrastive-video-representation-learning-with-temporally-adversarial-examples","children":[]},{"level":2,"title":"ExtreMA: Extreme Masking for Learning Instance and Distributed Visual Representations","slug":"extrema-extreme-masking-for-learning-instance-and-distributed-visual-representations","link":"#extrema-extreme-masking-for-learning-instance-and-distributed-visual-representations","children":[]},{"level":2,"title":"Broaden Your Views for Self-Supervised Video Learning","slug":"broaden-your-views-for-self-supervised-video-learning","link":"#broaden-your-views-for-self-supervised-video-learning","children":[]},{"level":2,"title":"Learning by Aligning Videos in Time","slug":"learning-by-aligning-videos-in-time","link":"#learning-by-aligning-videos-in-time","children":[]},{"level":2,"title":"Vi2CLR: Video and Image for Visual Contrastive Learning of Representation","slug":"vi2clr-video-and-image-for-visual-contrastive-learning-of-representation","link":"#vi2clr-video-and-image-for-visual-contrastive-learning-of-representation","children":[]},{"level":2,"title":"VIOLET : End-to-End Video-Language Transformers with Masked Visual-token Modeling","slug":"violet-end-to-end-video-language-transformers-with-masked-visual-token-modeling","link":"#violet-end-to-end-video-language-transformers-with-masked-visual-token-modeling","children":[]},{"level":2,"title":"BEVT: BERT Pretraining of Video Transformers","slug":"bevt-bert-pretraining-of-video-transformers","link":"#bevt-bert-pretraining-of-video-transformers","children":[]},{"level":2,"title":"TransRank: Self-supervised Video Representation Learning via Ranking-based Transformation Recognition","slug":"transrank-self-supervised-video-representation-learning-via-ranking-based-transformation-recognition","link":"#transrank-self-supervised-video-representation-learning-via-ranking-based-transformation-recognition","children":[]},{"level":2,"title":"Probabilistic Representations for Video Contrastive Learning: ProViCo","slug":"probabilistic-representations-for-video-contrastive-learning-provico","link":"#probabilistic-representations-for-video-contrastive-learning-provico","children":[]}],"git":{"createdTime":1697642418000,"updatedTime":1697642418000,"contributors":[{"name":"WillebrordSnell","email":"799976781@qq.com","commits":1}]},"readingTime":{"minutes":14.07,"words":4221},"filePathRelative":"keyan/videoRepresentation/_videoRepresentation.md","localizedDate":"2023年9月2日","excerpt":"<h1> 关于视频理解的论文收集(较新)</h1>\\n<p>本文可配合<a href=\\"/keyan/videoUnderstanding/_videoUnderstanding.html\\" target=\\"blank\\">视频理解综述性质记录</a>服用</p>\\n<h2> Swin Transformer: Hierarchical Vision Transformer using Shifted Windows</h2>\\n<blockquote>\\n<p>论文地址：<a href=\\"http://arxiv.org/abs/2103.14030\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">http://arxiv.org/abs/2103.14030</a><br>\\n项目代码：<a href=\\"https://github.com/microsoft/Swin-Transformer\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">https://github.com/microsoft/Swin-Transformer</a></p>\\n</blockquote>","autoDesc":true}');export{e as data};
