const o=JSON.parse('{"key":"v-04cae686","path":"/keyan/videoUnderstanding/videoUnderstanding.html","title":"视频理解综述性质的记录","lang":"zh-CN","frontmatter":{"date":"2023-10-09T00:00:00.000Z","category":["码头"],"tag":["视频理解","视频对话"],"description":"视频理解综述性质的记录 简介 视频数据本身就是一种多模态信息，并且是一种很丰富的数据来源，其包含的信息远远多于2D的图片，例如有物体移动的信息，以及长期的时序信息，音频信号等，并且视频数据是一种天生的数据增强，比如在一段视频中一个物体会有各种各样的变化，形变，遮挡，光照变化等，这种改变通常是十分丰富且自由的，远比通过一些图片处理得到的数据增强要自然的多。视频理解领域三巨头就是：Action Recognition、Temporal Action Localization、Spatio-Temporal Action Localization","head":[["meta",{"property":"og:url","content":"https://github.com/WillebrordSnell/keyan/videoUnderstanding/videoUnderstanding.html"}],["meta",{"property":"og:site_name","content":" "}],["meta",{"property":"og:title","content":"视频理解综述性质的记录"}],["meta",{"property":"og:description","content":"视频理解综述性质的记录 简介 视频数据本身就是一种多模态信息，并且是一种很丰富的数据来源，其包含的信息远远多于2D的图片，例如有物体移动的信息，以及长期的时序信息，音频信号等，并且视频数据是一种天生的数据增强，比如在一段视频中一个物体会有各种各样的变化，形变，遮挡，光照变化等，这种改变通常是十分丰富且自由的，远比通过一些图片处理得到的数据增强要自然的多。视频理解领域三巨头就是：Action Recognition、Temporal Action Localization、Spatio-Temporal Action Localization"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2023-10-18T15:20:18.000Z"}],["meta",{"property":"article:author","content":"Mr.R"}],["meta",{"property":"article:tag","content":"视频理解"}],["meta",{"property":"article:tag","content":"视频对话"}],["meta",{"property":"article:published_time","content":"2023-10-09T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2023-10-18T15:20:18.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"视频理解综述性质的记录\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2023-10-09T00:00:00.000Z\\",\\"dateModified\\":\\"2023-10-18T15:20:18.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Mr.R\\",\\"url\\":\\"https://github.com/WillebrordSnell\\"}]}"]]},"headers":[{"level":2,"title":"简介","slug":"简介","link":"#简介","children":[]},{"level":2,"title":"DeepVideo：Large-scale Video Classification with Convolutional Neural Networks","slug":"deepvideo-large-scale-video-classification-with-convolutional-neural-networks","link":"#deepvideo-large-scale-video-classification-with-convolutional-neural-networks","children":[]},{"level":2,"title":"双流网络：Two-Stream Convolutional Networks for Action Recognition in Videos (2014)","slug":"双流网络-two-stream-convolutional-networks-for-action-recognition-in-videos-2014","link":"#双流网络-two-stream-convolutional-networks-for-action-recognition-in-videos-2014","children":[]},{"level":2,"title":"Beyond-short-snippets：Beyond Short Snippets: Deep Networks for Video Classification","slug":"beyond-short-snippets-beyond-short-snippets-deep-networks-for-video-classification","link":"#beyond-short-snippets-beyond-short-snippets-deep-networks-for-video-classification","children":[]},{"level":2,"title":"Convolutional fusion：Beyond Short Snippets: Deep Networks for Video Classification","slug":"convolutional-fusion-beyond-short-snippets-deep-networks-for-video-classification","link":"#convolutional-fusion-beyond-short-snippets-deep-networks-for-video-classification","children":[]},{"level":2,"title":"TSN：Convolutional Two-Stream Network Fusion for Video Action Recognition","slug":"tsn-convolutional-two-stream-network-fusion-for-video-action-recognition","link":"#tsn-convolutional-two-stream-network-fusion-for-video-action-recognition","children":[]},{"level":2,"title":"C3D：Learning Spatiotemporal Features with 3D Convolutional Networks","slug":"c3d-learning-spatiotemporal-features-with-3d-convolutional-networks","link":"#c3d-learning-spatiotemporal-features-with-3d-convolutional-networks","children":[]},{"level":2,"title":"I3D：Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset","slug":"i3d-quo-vadis-action-recognition-a-new-model-and-the-kinetics-dataset","link":"#i3d-quo-vadis-action-recognition-a-new-model-and-the-kinetics-dataset","children":[]},{"level":2,"title":"Non-local：Non-local Neural Networks","slug":"non-local-non-local-neural-networks","link":"#non-local-non-local-neural-networks","children":[]},{"level":2,"title":"R(2+1)D：A Closer Look at Spatiotemporal Convolutions for Action Recognition","slug":"r-2-1-d-a-closer-look-at-spatiotemporal-convolutions-for-action-recognition","link":"#r-2-1-d-a-closer-look-at-spatiotemporal-convolutions-for-action-recognition","children":[]},{"level":2,"title":"SlowFast Networks for Video Recognition","slug":"slowfast-networks-for-video-recognition","link":"#slowfast-networks-for-video-recognition","children":[]},{"level":2,"title":"Is Space-Time Attention All You Need for Video Understanding?","slug":"is-space-time-attention-all-you-need-for-video-understanding","link":"#is-space-time-attention-all-you-need-for-video-understanding","children":[]}],"git":{"createdTime":1697642418000,"updatedTime":1697642418000,"contributors":[{"name":"WillebrordSnell","email":"799976781@qq.com","commits":1}]},"readingTime":{"minutes":19.51,"words":5854},"filePathRelative":"keyan/videoUnderstanding/_videoUnderstanding.md","localizedDate":"2023年10月9日","excerpt":"<h1> 视频理解综述性质的记录</h1>\\n<h2> 简介</h2>\\n<p>视频数据本身就是一种多模态信息，并且是一种很丰富的数据来源，其包含的信息远远多于2D的图片，例如有物体移动的信息，以及长期的时序信息，音频信号等，并且视频数据是一种天生的数据增强，比如在一段视频中一个物体会有各种各样的变化，形变，遮挡，光照变化等，这种改变通常是十分丰富且自由的，远比通过一些图片处理得到的数据增强要自然的多。视频理解领域三巨头就是：Action Recognition、Temporal Action Localization、Spatio-Temporal Action Localization</p>","autoDesc":true}');export{o as data};
