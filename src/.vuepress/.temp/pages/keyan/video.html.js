import comp from "E:/R-blog/src/.vuepress/.temp/pages/keyan/video.html.vue"
const data = JSON.parse("{\"path\":\"/keyan/video.html\",\"title\":\"一些关于video方向的论文收集\",\"lang\":\"zh-CN\",\"frontmatter\":{\"date\":\"2023-09-19T00:00:00.000Z\",\"category\":[\"科研\"],\"tag\":[\"去码头整点论文\"],\"description\":\"一些关于video方向的论文收集 本文主要记录一下近4年(2019年起)各顶会顶刊有关video的paper名字，以便后续video dialog工作的调研和展开 (本文档未经过任何筛选，仅通过关键词搜索得到paper名字) 2022 ECCV DexMV: Imitation Learning for Dexterous Manipulation f...\",\"head\":[[\"script\",{\"type\":\"application/ld+json\"},\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"Article\\\",\\\"headline\\\":\\\"一些关于video方向的论文收集\\\",\\\"image\\\":[\\\"\\\"],\\\"datePublished\\\":\\\"2023-09-19T00:00:00.000Z\\\",\\\"dateModified\\\":null,\\\"author\\\":[{\\\"@type\\\":\\\"Person\\\",\\\"name\\\":\\\"Mr.R\\\",\\\"url\\\":\\\"https://github.com/WillebrordSnell\\\"}]}\"],[\"meta\",{\"property\":\"og:url\",\"content\":\"https://mister-hope.github.io/keyan/video.html\"}],[\"meta\",{\"property\":\"og:site_name\",\"content\":\" \"}],[\"meta\",{\"property\":\"og:title\",\"content\":\"一些关于video方向的论文收集\"}],[\"meta\",{\"property\":\"og:description\",\"content\":\"一些关于video方向的论文收集 本文主要记录一下近4年(2019年起)各顶会顶刊有关video的paper名字，以便后续video dialog工作的调研和展开 (本文档未经过任何筛选，仅通过关键词搜索得到paper名字) 2022 ECCV DexMV: Imitation Learning for Dexterous Manipulation f...\"}],[\"meta\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"meta\",{\"property\":\"og:locale\",\"content\":\"zh-CN\"}],[\"meta\",{\"property\":\"article:tag\",\"content\":\"去码头整点论文\"}],[\"meta\",{\"property\":\"article:published_time\",\"content\":\"2023-09-19T00:00:00.000Z\"}]]},\"readingTime\":{\"minutes\":7.96,\"words\":2389},\"filePathRelative\":\"keyan/video.md\",\"excerpt\":\"\\n<p>本文主要记录一下近4年(2019年起)各顶会顶刊有关video的paper名字，以便后续video dialog工作的调研和展开<br>\\n(本文档未经过任何筛选，仅通过关键词搜索得到paper名字)</p>\\n<h3>2022 ECCV</h3>\\n<p>DexMV: Imitation Learning for Dexterous Manipulation from Human Videos<br>\\nVideo Dialog as Conversation About Objects Living in Space-Time<br>\\nActor-Centered Representations for Action Localization in Streaming Videos<br>\\nAutoTransition: Learning to Recommend Video Transition Effects<br>\\nSports Video Analysis on Large-Scale Data<br>\\nSemantic-Aware Implicit Neural Audio-Driven Video Portrait Generation<br>\\nQuantized GAN for Complex Music Generation from Dance Videos<br>\\nTelepresence Video Quality Assessment<br>\\nGAMa: Cross-View Video Geo-Localization<br>\\nFAR: Fourier Aerial Video Recognition<br>\\nFabric Material Recovery from Video Using Multi-scale Geometric Auto-Encoder<br>\\nVideo Graph Transformer for Video Question Answering<br>\\nVideo Question Answering with Iterative Video-Text Co-tokenization<br>\\nCan Shuffling Video Benefit Temporal Bias Problem: A Novel Training Framework for Temporal Grounding<br>\\nSelective Query-Guided Debiasing for Video Corpus Moment Retrieval<br>\\nLearning Linguistic Association Towards Efficient Text-Video Retrieval<br>\\nVisageSynTalk: Unseen Speaker Video-to-Speech Synthesis via Speech-Visage Feature Selection<br>\\nCycDA: Unsupervised Cycle Domain Adaptation to Learn from Image to Video<br>\\nExpanding Language-Image Pretrained Models for General Video Recognition<br>\\nAdaFocusV3: On Unified Spatial-Temporal Dynamic Video Recognition<br>\\nDelving into Details: Synopsis-to-Detail Networks for Video Recognition<br>\\nScale-Aware Spatio-Temporal Relation Learning for Video Anomaly Detection<br>\\nContinual 3D Convolutional Neural Networks for Real-time Processing of Videos<br>\\nGeometric Features Informed Multi-person Human-Object Interaction Recognition in Videos<br>\\nNeural Capture of Animatable 3D Human from Monocular Video<br>\\nFAST-VQA: Efficient End-to-End Video Quality Assessment with Fragment Sampling<br>\\nReal-RawVSR: Real-World Raw Video Super-Resolution with a Benchmark Dataset<br>\\nSynthesizing Light Field Video from Monocular Video<br>\\nVideo Interpolation by Event-Driven Anisotropic Adjustment of Optical Flow<br>\\nCelebV-HQ: A Large-Scale Video Facial Attributes Dataset<br>\\nSmoothNet: A Plug-and-Play Network for Refining Human Poses in Videos<br>\\nRayTran: 3D Pose Estimation and Shape Reconstruction of Multiple Objects from Videos with Ray-Traced Transformers<br>\\nSALISA: Saliency-Based Input Sampling for Efficient Video Object Detection<br>\\nVideo Anomaly Detection by Solving Decoupled Spatio-Temporal Jigsaw Puzzles<br>\\nWeakly-Supervised Temporal Action Detection for Fine-Grained Videos with Hierarchical Atomic Actions<br>\\nContrast-Phys: Unsupervised Video-Based Remote Physiological Measurement via Spatiotemporal Contrast<br>\\nHierarchical Contrastive Inconsistency Learning for Deepfake Video Detection<br>\\nGenerative Adversarial Network for Future Hand Segmentation from Egocentric Video<br>\\nMy View is the Best View: Procedure Learning from Egocentric Videos<br>\\nSelf-supervised Sparse Representation for Video Anomaly Detection<br>\\nFew-Shot Video Object Detection<br>\\nInductive and Transductive Few-Shot Video Classification via Appearance and Temporal Alignments<br>\\nGraph Neural Network for Cell Tracking in Microscopy Videos<br>\\nParticle Video Revisited: Tracking Through Occlusions Using Point Trajectories<br>\\nTowards Generic 3D Tracking in RGBD Videos: Benchmark and Baseline<br>\\nTackling Background Distraction in Video Object Segmentation<br>\\nLearned Variational Video Color Propagation<br>\\nEnsemble Learning Priors Driven Deep Unfolding for Scalable Video Snapshot Compressive Imaging<br>\\nBridging Images and Videos: A Simple Learning Framework for Large Vocabulary Video Object Detection<br>\\nLocVTP: Video-Text Pre-training for Temporal Localization<br>\\nLearning to Drive by Watching YouTube Videos: Action-Conditioned Contrastive Policy Pretraining<br>\\nStatic and Dynamic Concepts for Self-supervised Video Representation Learning<br>\\nNeural Video Compression Using GANs for Detail Synthesis and Propagation<br>\\nIs It Necessary to Transfer Temporal Knowledge for Domain Adaptive Video Semantic Segmentation?<br>\\nMeta Spatio-Temporal Debiasing for Video Scene Graph Generation<br>\\nPolyphonicFormer: Unified Query Learning for Depth-Aware Video Panoptic Segmentation<br>\\nVideo Restoration Framework and Its Meta-adaptations to Data-Poor Conditions<br>\\nSeqFormer: Sequential Transformer for Video Instance Segmentation<br>\\nIn Defense of Online Models for Video Instance Segmentation<br>\\nXMem: Long-Term Video Object Segmentation with an Atkinson-Shiffrin Memory Model<br>\\nVideo Mask Transfiner for High-Quality Video Instance Segmentation<br>\\nPoint Primitive Transformer for Long-Term 4D Point Cloud Video Understanding<br>\\nWaymo Open Dataset: Panoramic Video Panoptic Segmentation<br>\\nOne-Trimap Video Matting<br>\\nLearning Quality-aware Dynamic Memory for Video Object Segmentation<br>\\nInstance as Identity: A Generic Online Paradigm for Video Instance Segmentation<br>\\nBATMAN: Bilateral Attention Transformer in Motion-Appearance Neighboring Space for Video Object Segmentation<br>\\nGlobal Spectral Filter Memory Network for Video Object Segmentation<br>\\nVideo Instance Segmentation via Multi-Scale Spatio-Temporal Split Attention Transformer<br>\\nDomain Adaptive Video Segmentation via Temporal Pseudo Supervision<br>\\nGOCA: Guided Online Cluster Assignment for Self-supervised Video Representation Learning<br>\\nLearn2Augment: Learning to Composite Videos for Data Augmentation in Action Recognition<br>\\nFederated Self-supervised Learning for Video Understanding<br>\\nNeuMan: Neural Human Radiance Field from a Single Video<br>\\nStructure and Motion from Casual Videos<br>\\nThe Anatomy of Video Editing: A Dataset and Benchmark Suite for AI-Assisted Video Editing<br>\\nMUGEN: A Playground for Video-Audio-Text Multimodal Understanding and GENeration<br>\\nearning Omnidirectional Flow in 360$^\\\\circ $ Video via Siamese Representation<br>\\nPTSEFormer: Progressive Temporal-Spatial Enhanced TransFormer Towards Video Object Detection<br>\\nDual-Stream Knowledge-Preserving Hashing for Unsupervised Video Retrieval<br>\\nMulti-query Video Retrieval<br>\\nTS2-Net: Token Shift and Selection Transformer for Text-Video Retrieval<br>\\nLearning Audio-Video Modalities from Image Captions<br>\\nLightweight Attentional Feature Fusion: A New Baseline for Text-to-Video Retrieval<br>\\nAudio-Visual Mismatch-Aware Video Retrieval via Association and Adjustment<br>\\nCAViT: Contextual Alignment Vision Transformer for Video Object Re-identification<br>\\nRelighting4D: Neural Relightable Human from Videos<br>\\nReal-Time Intermediate Flow Estimation for Video Frame Interpolation<br>\\nDeep Bayesian Video Frame Interpolation<br>\\nA Perceptual Quality Metric for Video Frame Interpolation<br>\\nFast-Vid2Vid: Spatial-Temporal Compression for Video-to-Video Synthesis<br>\\nTemporally Consistent Semantic Video Editing<br>\\nError Compensation Framework for Flow-Guided Video Inpainting<br>\\nLearning Cross-Video Neural Representations for High-Quality Frame Interpolation<br>\\nA Style-Based GAN Encoder for High Fidelity Reconstruction of Images and Videos<br>\\nHarmonizer: Learning to Perform White-Box Image and Video Harmonization<br>\\nText2LIVE: Text-Driven Layered Image and Video Editing<br>\\nCANF-VC: Conditional Augmented Normalizing Flows for Video Compression<br>\\nVideo Extrapolation in Space and Time<br>\\nAugmentation of rPPG Benchmark Datasets: Learning to Remove and Embed rPPG Signals via Double Cycle Consistent Learning from Unpaired Facial Videos<br>\\nLayered Controllable Video Generation<br>\\nSpatio-Temporal Deformable Attention Network for Video Deblurring<br>\\nSound-Guided Semantic Video Generation<br>\\nControllable Video Generation Through Global and Local Motion Dynamics<br>\\nLong Video Generation with Time-Agnostic VQGAN and Time-Sensitive Transformer<br>\\nCombining Internal and External Constraints for Unrolling Shutter in Videos<br>\\nA Codec Information Assisted Framework for Efficient Compressed Video Super-Resolution<br>\\nDiverse Generation from a Single Video Made Possible<br>\\nLearning Shadow Correspondence for Video Shadow Detection<br>\\nFlow-Guided Transformer for Video Inpainting<br>\\nLearning Spatio-Temporal Downsampling for Effective Video Upscaling<br>\\nLearning Spatiotemporal Frequency-Transformer for Compressed Video Super-Resolution<br>\\nEfficient Meta-Tuning for Content-Aware Neural Video Delivery<br>\\nTowards Interpretable Video Super-Resolution via Alternating Optimization<br>\\nEvent-guided Deblurring of Unknown Exposure Time Videos<br>\\nUnidirectional Video Denoising by Mimicking Backward Recurrent Modules with Look-Ahead Forward Ones<br>\\nERDN: Equivalent Receptive Field Deformable Network for Video Deblurring<br>\\nRealFlow: EM-Based Realistic Optical Flow Dataset Generation from Videos<br>\\nEfficient Video Deblurring Guided by Motion Magnitude<br>\\nTempFormer: Temporally Consistent Transformer for Video Denoising<br>\\nRethinking Video Rain Streak Removal: A New Synthesis Model and a Deraining Network with Video Rain Prior<br>\\nAlphaVC: High-Performance and Efficient Learned Video Compression<br>\\nSource-Free Video Domain Adaptation by Learning Temporal Consistency for Action Recognition<br>\\nTowards Open Set Video Anomaly Detection<br>\\nEclipSE: Efficient Long-Range Video Retrieval Using Sight and Sound<br>\\nJoint-Modal Label Denoising for Weakly-Supervised Audio-Visual Video Parsing<br>\\nLess Than Few: Self-shot Video Instance Segmentation<br>\\nReal-Time Online Video Detection with Temporal Smoothing Transformers<br>\\nMining Relations Among Cross-Frame Affinities for Video Semantic Segmentation<br>\\nTL;DW? Summarizing Instructional Videos with Task Relevance and Cross-Modal Saliency<br>\\nDualFormer: Local-Global Stratified Transformer for Efficient Video Recognition<br>\\nHierarchical Feature Alignment Network for Unsupervised Video Object Segmentation<br>\\nPAC-Net: Highlight Your Video via History Preference Modeling<br>\\nHow Severe Is Benchmark-Sensitivity in Video Self-supervised Learning?<br>\\nNSNet: Non-saliency Suppression Sampler for Efficient Video Recognition<br>\\nVideo Activity Localisation with Uncertainties in Temporal Boundary<br>\\nTemporal Saliency Query Network for Efficient Video Recognition<br>\\nEfficient One-Stage Video Object Detection by Exploiting Temporal Consistency<br>\\nSpotting Temporally Precise, Fine-Grained Events in Video<br>\\nEfficient Video Transformers with Spatial-Temporal Token Selection<br>\\nLong Movie Clip Classification with State-Space Video Models<br>\\nPrompting Visual-Language Models for Efficient Video Understanding<br>\\nAsymmetric Relation Consistency Reasoning for Video Relation Grounding<br>\\nK-centered Patch Sampling for Efficient Video Recognition<br>\\nGraphVid: It only Takes a Few Nodes to Understand a Video<br>\\nDelta Distillation for Efficient Video Processing<br>\\nCOMPOSER: Compositional Reasoning of Group Activity in Videos with Keypoint-Only Modality<br>\\nE-NeRV: Expedite Neural Video Representation with Disentangled Spatial-Temporal Context<br>\\nTDViT: Temporal Dilated Video Transformer for Dense Video Tasks<br>\\nFlow Graph to Video Grounding for Weakly-Supervised Multi-step Localization<br>\\nMaCLR: Motion-Aware Contrastive Learning of Representations for Videos<br>\\nFrozen CLIP Models are Efficient Video Learners<br>\\nPanoramic Vision Transformer for Saliency Detection in 360$^\\\\circ $ Videos<br>\\nBayesian Tracking of Video Graphs Using Joint Kalman Smoothing and Registration<br>\\nMotion Sensitive Contrastive Learning for Self-supervised Video Representation<br>\\nDynamic Temporal Filtering in Video Models<br>\\nVTC: Improving Video-Text Retrieval with User Comments<br>\\nAutomatic Dense Annotation of Large-Vocabulary Sign Language Videos<br>\\nMILES: Visual BERT Pre-training with Injected Language Semantics for Video-Text Retrieval</p>\",\"autoDesc\":true}")
export { comp, data }

if (import.meta.webpackHot) {
  import.meta.webpackHot.accept()
  if (__VUE_HMR_RUNTIME__.updatePageData) {
    __VUE_HMR_RUNTIME__.updatePageData(data)
  }
}

if (import.meta.hot) {
  import.meta.hot.accept(({ data }) => {
    __VUE_HMR_RUNTIME__.updatePageData(data)
  })
}
